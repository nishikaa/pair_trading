{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45bfe8ae-1745-4eaf-9d12-fe6dab5e6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from pair_trading_foundations.data_generation import ExecutePairTrading, generate_training_data\n",
    "random.seed(23)\n",
    "import cProfile\n",
    "import pstats\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def chunker(seq, size):\n",
    "    # split a list into chunks\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05f8ad47-14f9-4351-bf7d-15597793e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('Data/sp500_full_20181231_to_20231229.csv')\n",
    "data = pd.read_csv('Data/sp500_full_20150101_to_20191231.csv')\n",
    "value_count_tb = data[['Ticker']].groupby('Ticker').size().reset_index()\n",
    "value_count_tb.columns = ['Ticker', 'Count']\n",
    "stock_to_keep = value_count_tb['Ticker'][value_count_tb.Count==value_count_tb.Count.max()]\n",
    "data = data[data.Ticker.isin(stock_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6a1c0-f52c-40cb-85e2-44b7fefd1bfc",
   "metadata": {},
   "source": [
    "# Generate for all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f14528-2e33-42a4-b3c5-77a32cdfd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list(set(data.Ticker.values))\n",
    "combinations = list(itertools.combinations(tickers, 2))\n",
    "len(combinations)\n",
    "batches = list(chunker(combinations, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64fa11-909b-413b-aadf-e01318df0ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in batches:\n",
    "    start_ts=time()\n",
    "    print(f'Getting {i+1}th out of {len(batches)} batches')\n",
    "    features_tb, labels_tb, pnl_metadata_tb = generate_training_data(\n",
    "        data=data,\n",
    "        training_len=300,\n",
    "        test_len=120,\n",
    "        calculate_label=True,\n",
    "        verbose=False,\n",
    "        combinations=batch\n",
    "    )\n",
    "    combined = pd.merge(features_tb, labels_tb, how='left', on=['Date', 'Ticker_P1','Ticker_P2']).reset_index(drop=True)\n",
    "    # combined = pd.merge(combined, pnl_metadata_tb[['Date', 'Ticker_P1','Ticker_P2', 'trade_executions']], how='left', on=['Date', 'Ticker_P1','Ticker_P2'])\n",
    "    # combined = combined[combined.pnls.notnull()].reset_index(drop=True)\n",
    "    combined.to_csv(f'Data/Training/pair_features{i+1}_300_120.csv', index=False)\n",
    "    end_ts = time()\n",
    "    print(f\"Took {end_ts - start_ts} seconds\")\n",
    "    i+=1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2001dcb-b0ec-495a-8522-75da6babdf11",
   "metadata": {},
   "source": [
    "# Generate data for sampled pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e4c7cf-719c-4409-8187-d7f575b94574",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tickers = random.sample(list(stock_to_keep.values), 50)\n",
    "# data_tech = data[data['GICS Sector'].isin(['Information Technology'])]\n",
    "data_sampled = data[data['Ticker'].isin(sampled_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865eb17-41ec-44b3-a696-c7b4c8b14e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225 stock pairs detected\n",
      "Took 0.03495192527770996 to initilize. Entering ticker pair loop\n",
      "Getting the 100th pair\n",
      "Used 231.58434414863586 for the 100 pairs\n",
      "Getting the 200th pair\n",
      "Used 239.58913803100586 for the 100 pairs\n"
     ]
    }
   ],
   "source": [
    "features_tb, labels_tb, pnl_metadata_tb = generate_training_data(\n",
    "        data=data_sampled,\n",
    "        training_len=300,\n",
    "        test_len=20,\n",
    "        calculate_label=True,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c14f98-ee57-49ab-99c8-0807baee5568",
   "metadata": {},
   "source": [
    "# Write data out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49af5b2-c494-4c04-9735-68ea8c716366",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df = pd.read_csv('Data/Training/1999-12-01-2023-12-31_SPY.csv')\n",
    "spy_df = spy_df[['Date','Adj Close']]\n",
    "spy_df.columns = ['Date','SPY_Close']\n",
    "\n",
    "look_forward_d = 20\n",
    "# Define a variable to calculate the return if we just buy SPY and sell in the next 60 days\n",
    "spy_return = []\n",
    "for i in range(spy_df.shape[0]):\n",
    "    if (i + look_forward_d) < spy_df.shape[0]:\n",
    "        spy_return.append(\n",
    "            100*(spy_df.loc[i+look_forward_d]['SPY_Close'] - spy_df.loc[i]['SPY_Close'])/spy_df.loc[i]['SPY_Close']\n",
    "        )\n",
    "    else:\n",
    "        spy_return.append(\n",
    "            np.nan\n",
    "        )\n",
    "spy_df['SPY_return'] = spy_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e44077-ea59-47d3-8470-6fb15b6ec440",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(features_tb, labels_tb, how='left', on=['Date', 'Ticker_P1','Ticker_P2']).reset_index(drop=True)\n",
    "combined = pd.merge(combined, spy_df[['Date','SPY_return']], how='left', on='Date')\n",
    "combined['pnls'] = combined.pnls * 100\n",
    "combined['successful_pair_trading'] = (combined.both_legs_profited) & (combined.pnls > combined.SPY_return)\n",
    "combined.both_legs_profited = combined.both_legs_profited.astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf6ef66-ad67-44da-82c6-7a1aa2757d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(f'Data/Training/pair_features_updated_300_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106cda4-3bb2-4fd3-abf1-40122feb4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = pd.merge(combined, pnl_metadata_tb[['Date', 'Ticker_P1','Ticker_P2', 'trade_executions']], how='left', on=['Date', 'Ticker_P1','Ticker_P2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44867a0b-987c-4561-b464-4950c920982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ea5fb-dc92-4825-ab87-f9bcf0a8154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1539825/1225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd20ab7-fc26-40b1-a739-1864714a874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/spotcheckout_output.pkl','wb') as file:\n",
    "    pickle.dump(combined, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72d072-48e4-411c-a31d-f54459140fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
