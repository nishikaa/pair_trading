{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bfe8ae-1745-4eaf-9d12-fe6dab5e6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from pair_trading_foundations.data_generation import ExecutePairTrading, generate_training_data\n",
    "random.seed(23)\n",
    "import cProfile\n",
    "import pstats\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def chunker(seq, size):\n",
    "    # split a list into chunks\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f8ad47-14f9-4351-bf7d-15597793e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('Data/sp500_full_20181231_to_20231229.csv')\n",
    "data = pd.read_csv('Data/sp500_full_20150101_to_20191231.csv')\n",
    "value_count_tb = data[['Ticker']].groupby('Ticker').size().reset_index()\n",
    "value_count_tb.columns = ['Ticker', 'Count']\n",
    "stock_to_keep = value_count_tb['Ticker'][value_count_tb.Count==value_count_tb.Count.max()]\n",
    "data = data[data.Ticker.isin(stock_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6a1c0-f52c-40cb-85e2-44b7fefd1bfc",
   "metadata": {},
   "source": [
    "# Generate for all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f14528-2e33-42a4-b3c5-77a32cdfd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list(set(data.Ticker.values))\n",
    "combinations = list(itertools.combinations(tickers, 2))\n",
    "len(combinations)\n",
    "batches = list(chunker(combinations, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64fa11-909b-413b-aadf-e01318df0ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in batches:\n",
    "    start_ts=time()\n",
    "    print(f'Getting {i+1}th out of {len(batches)} batches')\n",
    "    features_tb, labels_tb, pnl_metadata_tb = generate_training_data(\n",
    "        data=data,\n",
    "        training_len=300,\n",
    "        test_len=120,\n",
    "        calculate_label=True,\n",
    "        verbose=False,\n",
    "        combinations=batch\n",
    "    )\n",
    "    combined = pd.merge(features_tb, labels_tb, how='left', on=['Date', 'Ticker_P1','Ticker_P2']).reset_index(drop=True)\n",
    "    # combined = pd.merge(combined, pnl_metadata_tb[['Date', 'Ticker_P1','Ticker_P2', 'trade_executions']], how='left', on=['Date', 'Ticker_P1','Ticker_P2'])\n",
    "    # combined = combined[combined.pnls.notnull()].reset_index(drop=True)\n",
    "    combined.to_csv(f'Data/Training/pair_features{i+1}_300_120.csv', index=False)\n",
    "    end_ts = time()\n",
    "    print(f\"Took {end_ts - start_ts} seconds\")\n",
    "    i+=1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2001dcb-b0ec-495a-8522-75da6babdf11",
   "metadata": {},
   "source": [
    "# Generate data for sampled pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e4c7cf-719c-4409-8187-d7f575b94574",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tickers = random.sample(list(stock_to_keep.values), 50)\n",
    "# data_tech = data[data['GICS Sector'].isin(['Information Technology'])]\n",
    "data_sampled = data[data['Ticker'].isin(sampled_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1865eb17-41ec-44b3-a696-c7b4c8b14e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225 stock pairs detected\n",
      "Took 0.029092788696289062 to initilize. Entering ticker pair loop\n",
      "Getting the 100th pair\n",
      "Used 225.48755502700806 for the 100 pairs\n",
      "Getting the 200th pair\n",
      "Used 234.566015958786 for the 100 pairs\n",
      "Getting the 300th pair\n",
      "Used 240.5891661643982 for the 100 pairs\n",
      "Getting the 400th pair\n",
      "Used 280.18571400642395 for the 100 pairs\n",
      "Getting the 500th pair\n",
      "Used 332.15958523750305 for the 100 pairs\n",
      "Getting the 600th pair\n",
      "Used 379.5134711265564 for the 100 pairs\n",
      "Getting the 700th pair\n",
      "Used 433.6948826313019 for the 100 pairs\n",
      "Getting the 800th pair\n",
      "Used 409.1673150062561 for the 100 pairs\n",
      "Getting the 900th pair\n",
      "Used 540.499773979187 for the 100 pairs\n",
      "Getting the 1000th pair\n",
      "Used 605.3925397396088 for the 100 pairs\n",
      "Getting the 1100th pair\n",
      "Used 671.6702489852905 for the 100 pairs\n",
      "Getting the 1200th pair\n",
      "Used 513.206305027008 for the 100 pairs\n",
      "Took 5228.9714179039 to finish\n"
     ]
    }
   ],
   "source": [
    "features_tb, labels_tb, pnl_metadata_tb = generate_training_data(\n",
    "        data=data_sampled,\n",
    "        training_len=300,\n",
    "        test_len=20,\n",
    "        calculate_label=True,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c14f98-ee57-49ab-99c8-0807baee5568",
   "metadata": {},
   "source": [
    "# Write data out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49af5b2-c494-4c04-9735-68ea8c716366",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df = pd.read_csv('Data/Training/1999-12-01-2023-12-31_SPY.csv')\n",
    "spy_df = spy_df[['Date','Adj Close']]\n",
    "spy_df.columns = ['Date','SPY_Close']\n",
    "\n",
    "look_forward_d = 20\n",
    "# Define a variable to calculate the return if we just buy SPY and sell in the next 60 days\n",
    "spy_return = []\n",
    "for i in range(spy_df.shape[0]):\n",
    "    if (i + look_forward_d) < spy_df.shape[0]:\n",
    "        spy_return.append(\n",
    "            100*(spy_df.loc[i+look_forward_d]['SPY_Close'] - spy_df.loc[i]['SPY_Close'])/spy_df.loc[i]['SPY_Close']\n",
    "        )\n",
    "    else:\n",
    "        spy_return.append(\n",
    "            np.nan\n",
    "        )\n",
    "spy_df['SPY_return'] = spy_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e44077-ea59-47d3-8470-6fb15b6ec440",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(features_tb, labels_tb, how='left', on=['Date', 'Ticker_P1','Ticker_P2']).reset_index(drop=True)\n",
    "combined = pd.merge(combined, spy_df[['Date','SPY_return']], how='left', on='Date')\n",
    "combined['pnls'] = combined.pnls * 100\n",
    "# combined['successful_pair_trading'] = (combined.both_legs_profited) & (combined.pnls > combined.SPY_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf6ef66-ad67-44da-82c6-7a1aa2757d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(f'Data/Training/pair_features_300_20_l300meanstd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106cda4-3bb2-4fd3-abf1-40122feb4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = pd.merge(combined, pnl_metadata_tb[['Date', 'Ticker_P1','Ticker_P2', 'trade_executions']], how='left', on=['Date', 'Ticker_P1','Ticker_P2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44867a0b-987c-4561-b464-4950c920982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ea5fb-dc92-4825-ab87-f9bcf0a8154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1539825/1225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd20ab7-fc26-40b1-a739-1864714a874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/spotcheckout_output.pkl','wb') as file:\n",
    "    pickle.dump(combined, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72d072-48e4-411c-a31d-f54459140fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
