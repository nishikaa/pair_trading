{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2bb294",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fa2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "import ta\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "from pprint import pprint\n",
    "\n",
    "import gc\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/Training/pair_features_1_pairs500_300_120.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d22c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days = df.Date.nunique()\n",
    "total_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pnls.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a22f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_engineering(object):\n",
    "    def __init__(self):\n",
    "        super(feature_engineering, self).__init__()\n",
    "\n",
    "    def generate_technical_indicator(self, data_df): \n",
    "        '''\n",
    "        Function to generate additional technical indicators for the stock\n",
    "\n",
    "        Uses the \"statsmodels.tsa.stattools\" (as \"ts\") package to apply \n",
    "        the equations specified in the \"Technical Indicators\" markdown section \n",
    "        to stock closing data.\n",
    "        \n",
    "        Input:\n",
    "        data_df-- Dataframe containing stock finacials data\n",
    "        \n",
    "        Output:\n",
    "        Stock finacials data with added Dataframe of feature obtained from feature engineering\n",
    "        ''' \n",
    "        # 1. Momentum Indicators\n",
    "        # Relative Strength Index\n",
    "        df = data_df\n",
    "        df['rsi'] = ta.momentum.rsi(df['Close'], window=14)\n",
    "        # Kaufman’s Adaptive Moving Average (KAMA)\n",
    "        df['kama'] = ta.momentum.kama(df['Close'],window=14)\n",
    "\n",
    "        # 2. Volume Indicators\n",
    "        # Accumulation/Distribution Index (ADI)\n",
    "        df['adi'] = ta.volume.acc_dist_index(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "\n",
    "        # Volume-price trend (VPT)\n",
    "        df['vpt'] = ta.volume.volume_price_trend(df['Close'], df['Volume'])\n",
    "\n",
    "        # 3. Volatility Indicators\n",
    "        # Average True Range (ATR)\n",
    "        df['atr'] = ta.volatility.average_true_range(df['High'], df['Low'],df['Close'], window=14)\n",
    "\n",
    "        # Bollinger Bands (BB) N-period simple moving average (MA)\n",
    "        df['bb_ma'] = ta.volatility.bollinger_mavg(df['Close'], window=20)\n",
    "\n",
    "        # 4. Trend Indicators\n",
    "        # Average Directional Movement Index (ADX)\n",
    "        df['adx'] = ta.trend.adx(df['High'], df['Low'], df['Close'], window=14)\n",
    "\n",
    "        # Exponential Moving Average\n",
    "        df['ema'] = ta.trend.ema_indicator(df['Close'], window=14)\n",
    "\n",
    "        # Moving Average Convergence Divergence (MACD)\n",
    "        df['macd'] = ta.trend.macd(df['Close'], window_fast=14, window_slow=30)\n",
    "\n",
    "        # 5. Other Indicators\n",
    "        # Daily Log Return (DLR)\n",
    "        df['dlr'] = ta.others.daily_log_return(df['Close'])\n",
    "\n",
    "        # Daily Returns\n",
    "        df['daily_returns'] = df['Close'].pct_change()\n",
    "\n",
    "        # Moving Averages\n",
    "        averages = [50,200]\n",
    "        for avg in averages:\n",
    "            col_name = str(avg) +' Days Average'\n",
    "            df[col_name] = df['Close'].rolling(window = avg, center = False).mean()\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c971ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df = pd.read_csv('../../Data/Training/1999-12-01-2023-12-31_SPY.csv')\n",
    "spy_df = spy_df[['Date','Adj Close']]\n",
    "spy_df.columns = ['Date','SPY_Close']\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "spy_df['Date'] = pd.to_datetime(spy_df['Date']).dt.date\n",
    "df = pd.merge(df,spy_df,on='Date',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_obj = feature_engineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5717d7f",
   "metadata": {},
   "source": [
    "### Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers = df['Ticker_P1'].unique().tolist()+df['Ticker_P2'].unique().tolist()\n",
    "len(all_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e96224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta(rs,df,ticker,market):\n",
    "    rows = df.loc[rs.index]\n",
    "    sec_returns = np.log( df[[ticker,market]] / df[[ticker,market]].shift(1) ) \n",
    "\n",
    "    cov = sec_returns.cov() * 250\n",
    "    cov_with_market = cov.iloc[0,1]\n",
    "    market_var = sec_returns[market].var() * 250\n",
    "    beta = cov_with_market / market_var\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers_df_list = []\n",
    "for t in tqdm(all_tickers):\n",
    "    single_ticker_df = (df[df['Ticker_P1']==t] if t in df['Ticker_P1'].unique() else df[df['Ticker_P2']==t])\n",
    "    single_ticker_df = single_ticker_df.sort_values('Date')\n",
    "    single_ticker_df = single_ticker_df[['Date','Ticker_P1','Close_P1','High_P1','Low_P1','Volume_P1','SPY_Close']] if t in df['Ticker_P1'].unique() else\\\n",
    "                       single_ticker_df[['Date','Ticker_P2','Close_P2','High_P2','Low_P2','Volume_P2','SPY_Close']]\n",
    "    single_ticker_df.columns = ['Date','Ticker','Close','High','Low','Volume','SPY_Close']\n",
    "    single_ticker_df = single_ticker_df.drop_duplicates()\n",
    "\n",
    "    single_ticker_df['rolling_beta'] = single_ticker_df['Close'].rolling(300).progress_apply(compute_beta, \\\n",
    "                                        args=(single_ticker_df,'Close','SPY_Close'))\n",
    "\n",
    "    single_ticker_df_with_technical_indicators = fe_obj.generate_technical_indicator(single_ticker_df)\n",
    "    \n",
    "    all_tickers_df_list.append(single_ticker_df_with_technical_indicators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa4013-d6a1-486b-89cc-30bfaceea8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f2f8ee4",
   "metadata": {},
   "source": [
    "### Single Ticker Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers_df = pd.concat(all_tickers_df_list,axis=0,ignore_index=True).reset_index(drop=True)\n",
    "all_tickers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "all_tickers_df_P1_suffix = all_tickers_df.copy()\n",
    "all_tickers_df_P1_suffix.columns = ['Date','Ticker']+[c+'_P1' for c in all_tickers_df.columns if c not in ['Date','Ticker']]\n",
    "all_tickers_df_P2_suffix = all_tickers_df.copy()\n",
    "all_tickers_df_P2_suffix.columns = ['Date','Ticker']+[c+'_P2' for c in all_tickers_df.columns if c not in ['Date','Ticker']]\n",
    "\n",
    "df = pd.merge(df,all_tickers_df_P1_suffix,left_on=['Date','Ticker_P1'],right_on=['Date','Ticker'],\\\n",
    "              how='left',suffixes=['','_P1']).drop_duplicates()\n",
    "print(df.shape)\n",
    "df = pd.merge(df,all_tickers_df_P2_suffix,left_on=['Date','Ticker_P2'],right_on=['Date','Ticker'],\\\n",
    "              how='left',suffixes=['','_P2']).drop_duplicates()\n",
    "print(df.shape)\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9dc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1,20,30,60,90]:\n",
    "#     for c in ['num_entries','pnls']:\n",
    "#         df['PREV_'+str(i)+'_'+c] = df.groupby(['Ticker_P1','Ticker_P2'])[c].shift(20+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in ['num_entries','pnls']:\n",
    "#     df['PREV_'+c+'_mean'] = df[['PREV_1_'+c,'PREV_20_'+c,'PREV_30_'+c,'PREV_60_'+c,'PREV_90_'+c]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rsi_abs_spread'] = ta.momentum.rsi(df['abs_spread'], window=14)\n",
    "# Kaufman’s Adaptive Moving Average (KAMA)\n",
    "df['kama_abs_spread'] = ta.momentum.kama(df['abs_spread'],window=14)\n",
    "\n",
    "# 2. Volume Indicators\n",
    "# Accumulation/Distribution Index (ADI)\n",
    "# df['adi'] = ta.volume.acc_dist_index(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "\n",
    "# Volume-price trend (VPT)\n",
    "df['vpt_abs_spread'] = ta.volume.volume_price_trend(df['abs_spread'], np.log(df['Volume_P1'])+np.log(df['Volume_P2']))\n",
    "\n",
    "# 3. Volatility Indicators\n",
    "# Average True Range (ATR)\n",
    "# df['atr'] = ta.volatility.average_true_range(df['High'], df['Low'],df['Close'], window=14)\n",
    "\n",
    "# Bollinger Bands (BB) N-period simple moving average (MA)\n",
    "df['bb_ma_abs_spread'] = ta.volatility.bollinger_mavg(df['abs_spread'], window=20)\n",
    "\n",
    "# 4. Trend Indicators\n",
    "# Average Directional Movement Index (ADX)\n",
    "# df['adx'] = ta.trend.adx(df['High'], df['Low'], df['Close'], window=14)\n",
    "\n",
    "# Exponential Moving Average\n",
    "df['ema_abs_spread'] = ta.trend.ema_indicator(df['abs_spread'], window=14)\n",
    "\n",
    "# Moving Average Convergence Divergence (MACD)\n",
    "df['macd_abs_spread'] = ta.trend.macd(df['abs_spread'], window_fast=14, window_slow=30)\n",
    "\n",
    "# 5. Other Indicators\n",
    "# Daily Log Return (DLR)\n",
    "df['dlr_abs_spread'] = ta.others.daily_log_return(df['abs_spread'])\n",
    "\n",
    "# Daily Returns\n",
    "df['daily_returns_abs_spread'] = df['abs_spread'].pct_change()\n",
    "\n",
    "# Moving Averages\n",
    "averages = [50,200]\n",
    "for avg in averages:\n",
    "    col_name = str(avg) +' Days Average abs_spread'\n",
    "    df[col_name] = df['abs_spread'].rolling(window = avg, center = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Close', 'High', 'Low', 'Volume', 'rolling_beta', 'rsi', 'kama',\n",
    "       'adi', 'vpt', 'atr', 'bb_ma', 'adx', 'ema', 'macd', 'dlr',\n",
    "       'daily_returns', '50 Days Average', '200 Days Average']:\n",
    "# ,\n",
    "#        'sector_rolling_beta_mean', 'sector_rolling_beta_std',\n",
    "#        'sector_daily_return_mean', 'sector_daily_return_std']:\n",
    "    df['DIFF_'+c] = df[c+'_P1'] - df[c+'_P2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebac4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df['PCT_abs_spread_mean_l28_300'] = (df['abs_spread_mean_l28'] - df['abs_spread_mean'])/df['abs_spread_mean']\n",
    "# df['PCT_abs_spread_normed_median_l7'] = (df['abs_spread_normed_median'] - df['abs_spread_normed_l7_avg'])/df['abs_spread_normed_median']\n",
    "# df['PCT_abs_spread_normed_median_l4'] = (df['abs_spread_normed_median'] - df['abs_spread_normed_l14_avg'])/df['abs_spread_normed_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ca08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PCT_rolling_beta_P1'] = (df['rolling_beta_P1']-df.groupby('Ticker_P1')['rolling_beta_P1'].shift(20))/df.groupby('Ticker_P1')['rolling_beta_P1'].shift(20)\n",
    "df['PCT_rolling_beta_P2'] = (df['rolling_beta_P2']-df.groupby('Ticker_P2')['rolling_beta_P2'].shift(20))/df.groupby('Ticker_P2')['rolling_beta_P2'].shift(20)\n",
    "df['DIFF_secondary_rolling_beta'] = df['PCT_rolling_beta_P1']-df['PCT_rolling_beta_P2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock2vec = pd.read_csv('../../Data/Training/stock2vec.csv')\n",
    "stock2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36843247",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock2vec.columns = [c + '_P1' for c in stock2vec.columns]\n",
    "df = pd.merge(df,stock2vec,on='Ticker_P1',how='left')\n",
    "stock2vec.columns = [c[:-3] + '_P2' for c in stock2vec.columns]\n",
    "df = pd.merge(df,stock2vec,on='Ticker_P2',how='left')\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f531ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de330aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be a lot faster if we do it on pair level first then merge.\n",
    "\n",
    "vec1_sub1 = df[['STOCK2VEC_'+ str(i) + '_P1' for i in range(0,32)]]\n",
    "vec2_sub1 = df[['STOCK2VEC_'+ str(i) + '_P2' for i in range(0,32)]]\n",
    "cs = [np.dot(vec1_sub1.iloc[i], vec2_sub1.iloc[i]) / (norm(vec1_sub1.iloc[i]) * norm(vec2_sub1.iloc[i])) for i in tqdm(range(len(vec1_sub1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307dfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stock2vec_cos_sim'] = cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a08ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    df['FUTURE_abs_spread_'+str(i)] = df.groupby(['Ticker_P1','Ticker_P2'])['abs_spread'].shift(-1*i)\n",
    "\n",
    "df['FUTURE_abs_spread_avg'] = df[[c for c in df.columns if 'FUTURE_abs_spread_' in c]].mean(axis=1)\n",
    "\n",
    "# df['PCT_CHANGE'] = (df['FUTURE_abs_spread_avg'] - df['abs_spread'])*100.0/df['abs_spread']\n",
    "# df['direction'] = np.where(df['PCT_CHANGE'].abs()<3,0,np.where(df['PCT_CHANGE']>0,1,-1))\n",
    "# df['direction'] = np.where((df['FUTURE_abs_spread_avg'] - (df['abs_spread_mean']+1.5*df['abs_spread_std']))>0,1,0)\n",
    "df['entry_label1'] = np.where((df['FUTURE_abs_spread_avg'] - (df['abs_spread_mean']+1.5*df['abs_spread_std']))>0,1,0)\n",
    "\n",
    "df['entry_label1'].value_counts()\n",
    "# df['direction'] = df['PCT_CHANGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34febf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(9,12):\n",
    "    df['FUTURE_abs_spread_'+str(i)] = df.groupby(['Ticker_P1','Ticker_P2'])['abs_spread'].shift(-1*i)\n",
    "\n",
    "df['FUTURE_abs_spread_avg'] = df[[c for c in df.columns if 'FUTURE_abs_spread_' in c]].mean(axis=1)\n",
    "\n",
    "# df['PCT_CHANGE'] = (df['FUTURE_abs_spread_avg'] - df['abs_spread'])*100.0/df['abs_spread']\n",
    "# df['direction'] = np.where(df['PCT_CHANGE'].abs()<3,0,np.where(df['PCT_CHANGE']>0,1,-1))\n",
    "# df['direction'] = np.where((df['FUTURE_abs_spread_avg'] - (df['abs_spread_mean']+1.5*df['abs_spread_std']))>0,1,0)\n",
    "df['exit_label1'] = np.where((df['FUTURE_abs_spread_avg'] - (df['abs_spread_mean']+0.1*df['abs_spread_std']))<0,1,0)\n",
    "\n",
    "df['exit_label1'].value_counts()\n",
    "# df['direction'] = df['PCT_CHANGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([c for c in df.columns if 'FUTURE_abs_spread_' in c]+['FUTURE_abs_spread_avg'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop('vpt_abs_spread',axis=1)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dac58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan).isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f58663-e921-48b9-9f09-b77292fa3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abs_spread_log_mean_MA'] = np.log(df['abs_spread_mean_MA'])\n",
    "df['abs_spread_log_std_mean_MA'] = np.log(df['abs_spread_std_MA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9512e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d6c1e-6f48-43d8-885f-b0ec6a0b9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['abs_spread_log_mean_MA'] = np.log(X['abs_spread_mean_MA'])\n",
    "# X['abs_spread_log_std_mean_MA'] = np.log(X['abs_spread_std_MA'])\n",
    "# X = X.drop(['abs_spread_mean_MA', 'abs_spread_std_MA'],axis=1)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bfc33-ae8f-418b-9ed0-b8432e3c5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../Outputs/data_pipeline_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edade9",
   "metadata": {},
   "source": [
    "# Entry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b0e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'entry_label1'\n",
    "features_to_exclude = [] # ['High_P1', 'High_P2', 'Low_P1', 'Low_P2', 'abs_spread', 'abs_spread_mean', 'abs_spread_std']\n",
    "always_exclude = ['pnls', 'actual_abs_spread_std','actual_abs_spread','exit_label1']\n",
    "X = df\n",
    "y = df[label]\n",
    "\n",
    "X = X.drop(['Date', 'Ticker_P1', 'Ticker_P2', 'Volume_P1', 'Volume_P2', 'SPY_Close','Ticker',label]+\\\n",
    "           ['STOCK2VEC_'+ str(i) + '_P1' for i in range(0,32)]+\\\n",
    "           ['STOCK2VEC_'+ str(i) + '_P2' for i in range(0,32)],axis=1)\n",
    "X = X.drop(always_exclude, axis=1)\n",
    "X = X.drop(features_to_exclude, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['abs_spread_mean_MA', 'abs_spread_std_MA'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[X_train.index].Date.min(),df.loc[X_train.index].Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[X_val.index].Date.min(),df.loc[X_val.index].Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[X_test.index].Date.min(),df.loc[X_test.index].Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "X_val, y_val = undersample.fit_resample(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'boosting':'dart',\n",
    "        \"objective\": \"binary\",\n",
    "#         \"metric\": \"accuracy\",\n",
    "#         'class_weight':'balanced',\n",
    "        \"n_estimators\": 300,\n",
    "        \"verbosity\": -1,\n",
    "        \"bagging_freq\": 1,\n",
    "        'max_bin':trial.suggest_int('max_bin',64,1024),\n",
    "        'max_depth':trial.suggest_int('max_depth',4,20),\n",
    "\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 3000),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 1000),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, predictions, average='weighted')\n",
    "    return -1*f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72252d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best F1:', study.best_value*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1974e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = study.best_params\n",
    "hyper_params['boosting']='dart'\n",
    "hyper_params[\"objective\"] = \"binary\"\n",
    "# hyper_params[\"metric\"] = 'l2'\n",
    "#         'class_weight':'balanced',\n",
    "hyper_params[\"n_estimators\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier(**hyper_params)\n",
    "callbacks = [\\\n",
    "#             lgb.early_stopping(stopping_rounds=10, verbose=1,min_delta=0.001,first_metric_only=False), \n",
    "             lgb.log_evaluation(period=1)]\n",
    "\n",
    "gbm.fit(X_train,y_train, \n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='accuracy',\n",
    "        callbacks=callbacks,\n",
    "        feature_name = X_train.columns.tolist(),\n",
    "#         categorical_feature=categorical_features\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_preds = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023300c-a43f-4859-9007-308a2df830f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.feature_names = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131a053-6350-47e2-b26b-c8e095c41ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../Outputs/entry_model_latest.pkl','wb') as file:\n",
    "    pickle.dump(gbm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff84b09",
   "metadata": {},
   "source": [
    "# Exit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becabbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'exit_label1'\n",
    "features_to_exclude = [] # ['High_P1', 'High_P2', 'Low_P1', 'Low_P2', 'abs_spread', 'abs_spread_mean', 'abs_spread_std']\n",
    "always_exclude = ['pnls', 'actual_abs_spread_std','actual_abs_spread','entry_label1']\n",
    "X = df\n",
    "y = df[label]\n",
    "\n",
    "X = X.drop(['Date', 'Ticker_P1', 'Ticker_P2', 'Volume_P1', 'Volume_P2', 'SPY_Close','Ticker',label]+\\\n",
    "           ['STOCK2VEC_'+ str(i) + '_P1' for i in range(0,32)]+\\\n",
    "           ['STOCK2VEC_'+ str(i) + '_P2' for i in range(0,32)],axis=1)\n",
    "X = X.drop(always_exclude, axis=1)\n",
    "X = X.drop(features_to_exclude, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['abs_spread_mean_MA', 'abs_spread_std_MA'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[X_train.index].Date.min(),df.loc[X_train.index].Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[X_val.index].Date.min(),df.loc[X_val.index].Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[X_test.index].Date.min(),df.loc[X_test.index].Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "X_val, y_val = undersample.fit_resample(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e169198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'boosting':'dart',\n",
    "        \"objective\": \"binary\",\n",
    "#         \"metric\": \"accuracy\",\n",
    "#         'class_weight':'balanced',\n",
    "        \"n_estimators\": 300,\n",
    "        \"verbosity\": -1,\n",
    "        \"bagging_freq\": 1,\n",
    "        'max_bin':trial.suggest_int('max_bin',64,1024),\n",
    "        'max_depth':trial.suggest_int('max_depth',4,20),\n",
    "\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 3000),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 1000),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, predictions, average='weighted')\n",
    "    return -1*f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22475564",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best F1:', study.best_value*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = study.best_params\n",
    "hyper_params['boosting']='dart'\n",
    "hyper_params[\"objective\"] = \"binary\"\n",
    "# hyper_params[\"metric\"] = 'l2'\n",
    "#         'class_weight':'balanced',\n",
    "hyper_params[\"n_estimators\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_exit = lgb.LGBMClassifier(**hyper_params)\n",
    "callbacks = [\\\n",
    "#             lgb.early_stopping(stopping_rounds=10, verbose=1,min_delta=0.001,first_metric_only=False), \n",
    "             lgb.log_evaluation(period=1)]\n",
    "\n",
    "gbm_exit.fit(X_train,y_train, \n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='accuracy',\n",
    "        callbacks=callbacks,\n",
    "        feature_name = X_train.columns.tolist(),\n",
    "#         categorical_feature=categorical_features\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c5a08-d951-4a60-a524-028dba9c0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_exit.feature_names = X_train.columns\n",
    "with open('../../Outputs/exit_model_latest.pkl','wb') as file:\n",
    "    pickle.dump(gbm_exit, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba478b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_preds = gbm_exit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf25b5",
   "metadata": {},
   "source": [
    "# Spread model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6672aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'actual_abs_spread'\n",
    "features_to_exclude = [] # ['High_P1', 'High_P2', 'Low_P1', 'Low_P2', 'abs_spread', 'abs_spread_mean', 'abs_spread_std']\n",
    "always_exclude = ['pnls', 'actual_abs_spread_std','entry_label1','exit_label1']\n",
    "X = df\n",
    "y = df[label]\n",
    "\n",
    "X = X.drop(['Date', 'Ticker_P1', 'Ticker_P2', 'Volume_P1', 'Volume_P2', 'SPY_Close','Ticker',label]+\\\n",
    "           ['STOCK2VEC_'+ str(i) + '_P1' for i in range(0,32)]+\\\n",
    "           ['STOCK2VEC_'+ str(i) + '_P2' for i in range(0,32)],axis=1)\n",
    "X = X.drop(always_exclude, axis=1)\n",
    "X = X.drop(features_to_exclude, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['abs_spread_log_mean_MA'] = np.log(X['abs_spread_mean_MA'])\n",
    "X['abs_spread_log_std_mean_MA'] = np.log(X['abs_spread_std_MA'])\n",
    "X = X.drop(['abs_spread_mean_MA', 'abs_spread_std_MA'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f727972",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'boosting':'goss',\n",
    "        \"objective\": \"mae\",\n",
    "#         'device':'gpu',\n",
    "        \"metric\": 'l2',\n",
    "#         'class_weight':'balanced',\n",
    "        \"n_estimators\": 300,\n",
    "        \"verbosity\": -1,\n",
    "#         \"bagging_freq\": 1,\n",
    "        'max_bin':trial.suggest_int('max_bin',64,1024),\n",
    "        'max_depth':trial.suggest_int('max_depth',4,30),\n",
    "\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 3000),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 1000),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    mae = np.mean(abs(predictions-y_val))\n",
    "    mse = np.mean((predictions-y_val)**2)\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best mae:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = study.best_params\n",
    "hyper_params['boosting']='goss'\n",
    "hyper_params[\"objective\"] = \"mae\"\n",
    "# hyper_params[\"metric\"] = 'accuracy'\n",
    "#         'class_weight':'balanced',\n",
    "hyper_params[\"n_estimators\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "# gbm = lgb.LGBMClassifier(**hyper_params)\n",
    "\n",
    "callbacks = [\\\n",
    "#             lgb.early_stopping(stopping_rounds=10, verbose=1,min_delta=0.001,first_metric_only=False), \n",
    "             lgb.log_evaluation(period=1)]\n",
    "\n",
    "gbm.fit(X_train,y_train, \n",
    "        eval_set=[(X_val, y_val )],\n",
    "#         eval_metric='l1',\n",
    "        callbacks=callbacks,\n",
    "#         feature_name = features,\n",
    "#         categorical_feature=categorical_features\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = gbm.feature_importances_\n",
    "importances = pd.Series(importances,index=X_train.columns).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=[20,14])\n",
    "importances.plot.barh(ax=ax)\n",
    "ax.set_title(\"Feature Importance by Gain\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_result = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac58135",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(pd.concat([pd.Series(inference_result),y_test]).reset_index(drop=True))\n",
    "plot_df.columns=['value']\n",
    "plot_df['color'] = ['preds']*len(inference_result)+['true']*len(y_test)\n",
    "plot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f7aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(plot_df,x='value',color='color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'preds':inference_result,'true':y_test})\n",
    "results.index = X_test.index\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16644b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_pair = df.loc[X_test.index][(df['Ticker_P1']==df.loc[X_test.index]['Ticker_P1'].iloc[-1])&\\\n",
    "                                (df['Ticker_P2']==df.loc[X_test.index]['Ticker_P2'].iloc[-1])].index\n",
    "one_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151551ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(results.loc[one_pair],results.loc[one_pair].index,y=results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_mae = (inference_result[:len(y_test)] - y_test).abs().mean()\n",
    "gbm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90131cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf58a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = gbm_mae / y_test.abs().mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ea60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d1f20",
   "metadata": {},
   "source": [
    "# Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_test.index, 'entry_preds'] = entry_preds\n",
    "df.loc[X_test.index, 'exit_preds'] = exit_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce31fc-fc66-454d-ade8-b7eabcd9e169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the PNL from predicted spread\n",
    "from pair_trading_foundations.data import ExecutePairTrading\n",
    "\n",
    "BacktestData = df.loc[X_test.index]\n",
    "\n",
    "samples = BacktestData\n",
    "samples = samples.drop(['Date', 'Ticker_P1', 'Ticker_P2', 'Volume_P1', 'Volume_P2','SPY_Close','Ticker', label]+\\\n",
    "                       ['STOCK2VEC_'+ str(i) + '_P1' for i in range(0,32)]+\\\n",
    "                       ['STOCK2VEC_'+ str(i) + '_P2' for i in range(0,32)],axis=1)\n",
    "samples = samples.drop(always_exclude,axis=1)\n",
    "samples = samples.drop(features_to_exclude,axis=1)\n",
    "# samples['abs_spread_log_mean_MA'] = np.log(samples.abs_spread_mean_MA)\n",
    "# samples['abs_spread_log_std_mean_MA'] = np.log(samples.abs_spread_std_MA)\n",
    "# samples = samples.drop(['abs_spread_mean_MA', 'abs_spread_std_MA'],axis=1)\n",
    "\n",
    "\n",
    "model_input = np.reshape(samples, (samples.shape[0], 1, samples.shape[1])).astype(np.float32)\n",
    "# inference_result = lstm_model.predict(model_input).flatten()\n",
    "# inference_result = gbm.predict(samples[X_test.columns])\n",
    "BacktestData['pred_abs_spread'] = np.exp(inference_result)\n",
    "BacktestData['z_score'] = (np.log(BacktestData['pred_abs_spread']) / BacktestData['abs_spread_std_MA'])\n",
    "BacktestData = BacktestData.reset_index(drop=True)\n",
    "BacktestData = BacktestData.drop(['actual_abs_spread', 'actual_abs_spread_std'], axis=1)\n",
    "BacktestData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnls = []\n",
    "entry_signal = 2    # Make sure this matches with data pipeline\n",
    "exit_signal = 0.5   # Make sure this matches with data pipeline\n",
    "test_len = 60       # Make sure this matches with data pipeline\n",
    "for idx in tqdm(range(BacktestData.shape[0])):\n",
    "    if (idx > BacktestData.shape[0]-test_len-1):\n",
    "        pnls.append(np.nan)\n",
    "    else:\n",
    "        current_row = BacktestData.loc[idx]\n",
    "        result = ExecutePairTrading(current_row.pred_abs_spread,   # Use predicted spread\n",
    "                                    current_row.abs_spread_std_MA, # Use current std deviation\n",
    "                                    entry_signal=entry_signal,\n",
    "                                    exit_signal=exit_signal\n",
    "                                ).execute(\n",
    "                                    # Forward window\n",
    "                                    vec1=BacktestData.loc[(idx+1):(idx+test_len)]['Close_P1'].values,\n",
    "                                    vec2=BacktestData.loc[(idx+1):(idx+test_len)]['Close_P2'].values,\n",
    "                                    dates=BacktestData.loc[(idx+1):(idx+test_len)]['Date'].values,\n",
    "                                    base_fund=100,\n",
    "                                )\n",
    "\n",
    "        pnls.append(result.final_pl_pct)\n",
    "\n",
    "BacktestData['pred_pnls'] = pnls\n",
    "BacktestData = BacktestData.dropna()\n",
    "\n",
    "strategy = BacktestData.loc[(abs(BacktestData['z_score']) > 0.95) & (BacktestData['pred_pnls'] > 0)]\n",
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa31218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = BacktestData.loc[(abs(BacktestData['z_score']) > 0.95) & (BacktestData['pred_pnls'] > 0)]\n",
    "strategy = BacktestData.iloc[:-150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strategy.shape)\n",
    "strategy = strategy[strategy['entry_preds']==1]\n",
    "print(strategy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1459b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strategy.shape)\n",
    "strategy = strategy[strategy['exit_preds']==1]\n",
    "print(strategy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a239b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strategy.shape)\n",
    "strategy = strategy[strategy['stock2vec_cos_sim']>=0.8]\n",
    "print(strategy.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BacktestData.iloc[:-150000].Date.min(),BacktestData.iloc[:-150000].Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(strategy):\n",
    "    pnl_filters = strategy.filter(items=['Date', 'pnls', 'pred_pnls'])\n",
    "    pnl_filters = pnl_filters.rename(columns={'pnls': 'actual_PNLS', 'pred_pnls': 'predicted_PNLS'})\n",
    "#     ax = pnl_filters.plot(x='Date',y=['predicted_PNLS'],  linestyle='-', marker='o', color='red')\n",
    "#     pnl_filters.plot(x='Date',y=['actual_PNLS'], kind='bar', ax=ax)\n",
    "#     ax.set_title('Predicted pnls over actual')\n",
    "#     plt.figure(figsize=(8,6))\n",
    "#     plt.show()\n",
    "else:\n",
    "    print('No valid entry available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ff5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Execute each recommended trade by X amount\n",
    "if len(strategy):\n",
    "    average_pnl = pnl_filters.actual_PNLS.sum() / len(pnl_filters.actual_PNLS)\n",
    "    print('Returns: ', average_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Execute top 10 recommended trade by X amount\n",
    "if len(strategy):\n",
    "    best_num = 10\n",
    "    pnl_filters = pnl_filters.reset_index(drop=True)\n",
    "    # Get the top 10 predictions for PNL\n",
    "    sorted_indices = pnl_filters.predicted_PNLS.argsort()[::-1]\n",
    "    top_k = sorted_indices[sorted_indices < best_num]\n",
    "\n",
    "    # Retrieve the actual PNL\n",
    "    average_pnl = pnl_filters.actual_PNLS[top_k].sum() / best_num\n",
    "    print('Returns: ', average_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality test\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "# normality test\n",
    "stat, p = shapiro(inference_result)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D’Agostino’s K^2 Test\n",
    "from scipy.stats import normaltest\n",
    "# normality test\n",
    "stat, p = normaltest(inference_result)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderson-Darling Test\n",
    "from scipy.stats import anderson\n",
    "result = anderson(inference_result)\n",
    "print('Statistic: %.3f' % result.statistic)\n",
    "p = 0\n",
    "for i in range(len(result.critical_values)):\n",
    "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "if result.statistic < result.critical_values[i]:\n",
    "    print('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n",
    "else:\n",
    "    print('%.3f: %.3f, data does not look normal (reject H0)' % (sl, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb241102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
